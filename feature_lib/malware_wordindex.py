#Published:2018/09/03
#Ref:https://www.freebuf.com/articles/system/182566.html
import os
import pandas as pd
import datetime
import numpy as np
from keras.preprocessing.text import Tokenizer
from lib.preprocessing import Cuckoo2Txt
from lib.load import load_data_and_labels
class demo:
    def __init__(self,document_length_limit=1000,dev_sample_percentage=0.1):
        print("[+] Init module malware_wordindex  ")
        # params:preprocessing cuckoo report.josn to txt
        #self.report_path = "data/malware/cuckoo_reports"
        self.dst_path = "data/malware/cuckoo_report_txts"

        # params:load txt from dirs
        self.positive_data_dir = "data/malware/train/pos"
        self.negative_data_dir = "data/malware/train/neg"
        self.data_dirs = [self.negative_data_dir, self.positive_data_dir]
        self.document_length_limit = document_length_limit
        self.is_line_as_word = True
        self.dev_sample_percentage = dev_sample_percentage # function:train vs valid

        # params:embeddings network params to trainning model
        self.max_log_length=1024
        self.input_dim=3000
        self.output_dim=32

    def pre_processing(self,report_path="data/malware/cuckoo_reports"):
        print("[+] Start Preprocessing")
        obj = Cuckoo2Txt(report_path, self.dst_path)
        obj.cuckoo2txt()
        print("[+] Start Load Data")
        pre_x, pre_y = load_data_and_labels(self.data_dirs, self.document_length_limit, self.is_line_as_word)
        return pre_x,pre_y

    def pre_plot(self):
        pass

    def fxy_train(self,X,Y):
        print("[+] Start feature engineering for trainning")
        document_length_limit=self.document_length_limit
        max_document_length = max([len(text.split(" ")) for text in X])
        #print("max_docment_length: {}".format(max_document_length))
        max_document_length = min(document_length_limit, max_document_length)
        #print("max_docment_length: {}".format(max_document_length))
        vocab_processor=Tokenizer(max_document_length)
        vocab_processor.fit_on_texts(X)
        X=np.array(vocab_processor.texts_to_sequences(X))
        self.input_dim = len(vocab_processor.word_index)+1
        print("[+] Done!Successfully got Feature X Y")
        print("[+] Fxy shape:",X.shape,Y.shape)
        return X,Y

    def fxy_test(self):
        pass

    def fxy_plot(self):
        pass

    def model_train(self):
        pass

    def model_test(self):
        pass

    

